<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>cuda初识</title>
      <link href="/2020/10/05/cuda_article1/"/>
      <url>/2020/10/05/cuda_article1/</url>
      
        <content type="html"><![CDATA[<p>CUDA(Compute Unified Device Architecture): 统一计算架构，是GPU的编程接口。 CUDA是C语言的一种扩展，它允许使用标准C来进行GPU代码编程。这个代码即适用于主机处理器（CPU），也适用于设备处理器（GPU）。</p><p>CPU负责派生出运行在GPU设备处理器的多线程任务（CUDA称其为内核程序）。GPU设有内部调度器来把这些内核程序分配到相应的GPU硬件上。</p><p>CUDA的编译原则：基于虚拟指令集的运行时编译。</p><p>GPU并不是一个独立运行的计算平台，而需要与CPU协同工作，可以堪称是CPU的协处理器，因此GPU并行计算，是指CPU+GPU的异构计算架构。在异构计算架构中，GPU与CPU通过PCI-E总线连接在一起来协同工作，CPU所在的位置称为主机端（host），而GPU所在的位置称为设备端（device）。</p><p><img src="image/df49a98a67c5b8ce55f1a9afcf21d982.png" alt="df49a98a67c5b8ce55f1a9afcf21d982.png"></p><p>GPU适合数据并行的计算密集型任务，CPU适合控制密集型任务。</p><p>一、弗林分类法：对计算机架构进行划分</p><ul><li><p>SISD——单指令，单数据</p></li><li><p>SIMD——单指令，多数据</p></li><li><p>MISD——多指令，单数据</p></li><li><p>MIMD——多指令，多数据</p></li></ul><p>GPU实现的是“单指令，多线程”（SIMT，Single Instruction Multiple Thread）模型。</p><p>SIMT和SIMD本质相同：都是单指令多数据。SIMT比SIMD更灵活，允许一条指令的多数据分开寻址，SIMD是必须连续在一起的片段。</p><p>二、常用的并行模式</p><p>1、基于循环的模式：最关键的是发现循环间隐藏的依赖关系</p><p>2、派生/汇集模式</p><p>3、分条/分块</p><p>4、分而治之</p><p>三、CUDA编程模型基础</p><pre><code>CUDA是NVIDIA公司所开发的GPU编程模型，它提供了GPU编程的简易接口，基于CUDA编程可以构建基于GPU计算的应用程序。CUDA提供了对其它编程语言的支持，如C/C++，Python，Fortran等语言。CUDA编程模型是一个异构模型，需要CPU和GPU协同工作。在CUDA中，host和device是两个重要的概念，我们用host指代CPU及其内存，而用device指代GPU及其内存。</code></pre><p>1、CUDA程序的执行流程：</p><ul><li><p>分配host内存，并进行数据初始化；</p></li><li><p>分配device内存，并从host将数据拷贝到device上；</p></li><li><p>调用CUDA的核函数在device上完成指定的运算；</p></li><li><p>将device上的运算结果拷贝到host上；</p></li><li><p>释放device和host上分配的内存。</p></li></ul><p>2、核函数</p><pre><code>并行计算是通过调用CUDA的核函数来执行的。kernel是device上线程中并行执行的函数，核函数用__global__符号声明，在调用时需要用&lt;&lt;&lt;grid, block&gt;&gt;&gt;来制定kernel要执行的线程数量。首先GPU上很多并行化的轻量级线程。kernel在device上执行时实际上是启动很多线程，一个kernel所启动的所有线程称为一个网格（grid），同一个网格上的线程共享相同的全局内存空间，grid是线程结构的第一层次，而网格又可以分为很多线程块（block），一个线程块里面包含很多线程，这是第二个层次。线程两层组织结构如下图所示，这是一个gird和block均为2-dim的线程组织。grid和block都是定义为dim3类型的变量，dim3可以看成是包含三个无符号整数（x，y，z）成员的结构体变量，在定义时，缺省值初始化为1。因此grid和block可以灵活地定义为1-dim，2-dim以及3-dim结构。</code></pre><p><img src="image/aa6aa453ff39aa7078dde59b59b512d8.png" alt="aa6aa453ff39aa7078dde59b59b512d8.png"></p><p>每个图形卡（gpu）由若干个流处理器簇（Streaming Multiprocessor, SM）组成。SM的核心组件包括CUDA核心，共享内存，寄存器等。每个SM由若干个流处理器（Stream Processor, SP）组成。SM可以并发执行多个线程，并发能力取决于SM所拥有的资源数量。一个SM一般可以调度多个线程块，SM采用的是SIMT架构，基本的执行单元是线程束（warp）,一个warp有32个线程，线程束中的线程同时执行相同的指令。一个线程块被调度到一个SM中执行。线程块内的线程之间的数据交换由SM或者SP控制，线程块之间的数据交换由内核函数/主机程序控制。</p><p>一个sp执行一个线程。</p><p>四、gpu多线程与cpu多线程的区别</p><p>1、gpu支持细力度的并行，cpu支持粗力度的并行</p><p>2、支持线程的方式不同：cpu每个核只有少量寄存器，每个寄存器都将在执行任何已分配的任务中用到。为了能执行不同的人物，cpu将在任务与任务之间进行快速的上下文切换。从时间角度来看，cpu上下文切换的代价是昂贵的。gpu同样用到上下文切换这个概念，但它拥有多个寄存器组而不是单个寄存器组。因此，一次上下文切换只需设置一个寄存器组调度者，用于将当前寄存器组里的内容换进、换出。</p><p>3、gpu和cpu都需要处理失速状态：这种现象通常是由I/O操作和内存获取引起的。失速是指由于种种原因处于闲置状态，导致效率的急剧下降。如果有很多小任务，每一个都会在一小段时间后阻塞，那么cpu将花费大量的时间在上下文切换上，而只有少部分时间在做有用的工作。cpu的调度策略是基于时间分片，将时间平均分配给每个线程。一旦线程的数量增加，上下文切换的时间百分比就会增加，那么效率就会急剧下降。gpu采用数据并行的模式，需要成千上万的线程实现高效的工作。它利用有效的工作池来保证一直有事可做，不会出现闲置状态。因此，当GPU遇到内存获取操作或在等待计算结果时，流处理器就会切换到另一个指令流，而在之后再执行之前被阻塞的指令。</p><p>4、单核cpu每次同时运行一个线程，一个SM每次运行的warp数由warp调度器决定。</p><p>5、cpu遵循“缓存一致性”原则，gpu是非缓存一致性。</p><p>附加：</p><ol><li>上下文切换的理解：内核（操作系统的核心）在CPU上对进程或线程进行切换，或者说对于一组寄存器进行内容的换入、换出。</li></ol><p><a href="https://baike.baidu.com/item/%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2/4842616?fr=aladdin#3" target="_blank" rel="noopener">更清楚的理解请点击这里</a></p><ol start="2"><li><p>轻量级线程和重量级线程：</p></li><li><p>帮助理解sm、sp、warp的链接：<a href="https://blog.csdn.net/LG1259156776/article/details/52804840" target="_blank" rel="noopener">cuda thread、block、warp、sm、sp的理解</a>、<a href="https://blog.csdn.net/mzh_zju/article/details/82633015" target="_blank" rel="noopener">一个warp的理解</a>、<a href="https://blog.csdn.net/u011442652/article/details/41075657" target="_blank" rel="noopener">sm、sp、warp理解</a></p></li></ol>]]></content>
      
      
      <categories>
          
          <category> cuda学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cuda </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《动手学深度学习》笔记 Task05_卷积神经网络基础；leNet；卷积神经网络进阶</title>
      <link href="/2020/02/18/article5/"/>
      <url>/2020/02/18/article5/</url>
      
        <content type="html"><![CDATA[<h1 id="一、卷积神经网络基础"><a href="#一、卷积神经网络基础" class="headerlink" title="一、卷积神经网络基础"></a><strong>一、卷积神经网络基础</strong></h1><p><strong>主要内容：<br>1.二维卷积层<br>2.填充和步幅<br>3.多输入通道和多输出通道<br>4.池化</strong></p><h2 id="1-二维卷积层"><a href="#1-二维卷积层" class="headerlink" title="1.二维卷积层"></a>1.二维卷积层</h2><p>二维卷积层常用于处理图像数据。</p><h3 id="1-1-二维互相关运算"><a href="#1-1-二维互相关运算" class="headerlink" title="1.1 二维互相关运算"></a>1.1 二维互相关运算</h3><p>二维互相关（cross-correlation）运算的输入是一个二维输入数组和一个二维核（kernel）数组，输出也是一个二维数组，其中核数组通常称为卷积核或过滤器（filter）。卷积核的尺寸通常小于输入数组，卷积核在输入数组上滑动，在每个位置上，卷积核与该位置处的输入子数组按元素相乘并求和，得到输出数组中相应位置的元素。图1展示了一个互相关运算的例子，阴影部分分别是输入的第一个计算区域、核数组以及对应的输出。<br><img src="https://img-blog.csdnimg.cn/20200218162551163.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h3 id="1-2-二维卷积层"><a href="#1-2-二维卷积层" class="headerlink" title="1.2 二维卷积层"></a>1.2 二维卷积层</h3><p>二维卷积层将输入和卷积核做互相关运算，并加上一个标量偏置来得到输出。卷积层的模型参数包括卷积核和标量偏置。</p><h3 id="1-3-互相关运算与卷积运算"><a href="#1-3-互相关运算与卷积运算" class="headerlink" title="1.3 互相关运算与卷积运算"></a>1.3 互相关运算与卷积运算</h3><p>卷积层得名于卷积运算，但卷积层中用到的并非卷积运算而是互相关运算。我们将核数组上下翻转、左右翻转，再与输入数组做互相关运算，这一过程就是卷积运算。由于卷积层的核数组是可学习的，所以使用互相关运算与使用卷积运算并无本质区别。</p><h3 id="1-4-特征图与感受野"><a href="#1-4-特征图与感受野" class="headerlink" title="1.4 特征图与感受野"></a>1.4 特征图与感受野</h3><p>二维卷积层输出的二维数组可以看作是输入在空间维度（宽和高）上某一级的表征，也叫特征图（feature map）。影响元素的前向计算的所有可能输入区域（可能大于输入的实际尺寸）叫做x的感受野（receptive field）。</p><h2 id="2-填充和步幅"><a href="#2-填充和步幅" class="headerlink" title="2.填充和步幅"></a>2.填充和步幅</h2><p>卷积层的两个超参数，即填充和步幅，它们可以对给定形状的输入和卷积核改变输出形状。</p><h2 id="2-1-填充"><a href="#2-1-填充" class="headerlink" title="2.1 填充"></a>2.1 填充</h2><p>填充（padding）是指在输入高和宽的两侧填充元素（通常是0元素），图2里我们在原输入高和宽的两侧分别添加了值为0的元素。<br><img src="https://img-blog.csdnimg.cn/2020021816280896.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>图2 在输入的高和宽两侧分别填充了0元素的二维互相关计算。<br><img src="https://img-blog.csdnimg.cn/20200218162829456.png" alt="在这里插入图片描述"><br>我们在卷积神经网络中使用奇数高宽的核，比如3 * 3，5 * 5的卷积核，对于高度（或宽度）为大小为2k+1的核，令步幅为1，在高（或宽）两侧选择大小为的填充，便可保持输入与输出尺寸相同。</p><h2 id="2-2-步幅"><a href="#2-2-步幅" class="headerlink" title="2.2 步幅"></a>2.2 步幅</h2><p>在互相关运算中，卷积核在输入数组上滑动，每次滑动的行数与列数即是步幅（stride）。此前我们使用的步幅都是1，图3展示了在高上步幅为3、在宽上步幅为2的二维互相关运算。</p><p><img src="https://img-blog.csdnimg.cn/20200218163001286.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h3 id="2-2-1-数据集"><a href="#2-2-1-数据集" class="headerlink" title="2.2.1 数据集"></a>2.2.1 数据集</h3><p>我们通常收集一系列的真实数据，例如多栋房屋的真实售出价格和它们对应的面积和房龄。我们希望在这个数据上面寻找模型参数来使模型的预测价格与真实价格的误差最小。在机器学习术语里，该数据集被称为训练数据集（training data set）或训练集（training set），一栋房屋被称为一个样本（sample），其真实售出价格叫作标签（label），用来预测标签的两个因素叫作特征（feature）。特征用来表征样本的特点。</p><h3 id="2-2-2-损失函数"><a href="#2-2-2-损失函数" class="headerlink" title="2.2.2 损失函数"></a>2.2.2 损失函数</h3><p>模型训练中，我们需要衡量价格预测值与真实值之间的误差。通常我们会选取一个非负数作为误差，且数值越小表示误差越小。一个常用的选择是平方函数。 它在评估索引为  i  的样本误差的表达式为<br><img src="https://img-blog.csdnimg.cn/2020021413334554.jpg" alt="在这里插入图片描述"></p><h3 id="2-2-3-优化函数-随机梯度下降"><a href="#2-2-3-优化函数-随机梯度下降" class="headerlink" title="2.2.3 优化函数 - 随机梯度下降"></a>2.2.3 优化函数 - 随机梯度下降</h3><p>当模型和损失函数形式较为简单时，上面的误差最小化问题的解可以直接用公式表达出来。这类解叫作解析解（analytical solution）。本节使用的线性回归和平方误差刚好属于这个范畴。然而，大多数深度学习模型并没有解析解，只能通过优化算法有限次迭代模型参数来尽可能降低损失函数的值。这类解叫作数值解（numerical solution）。</p><p>在求数值解的优化算法中，小批量随机梯度下降（mini-batch stochastic gradient descent）在深度学习中被广泛使用。它的算法很简单：先选取一组模型参数的初始值，如随机选取；接下来对参数进行多次迭代，使每次迭代都可能降低损失函数的值。在每次迭代中，先随机均匀采样一个由固定数目训练数据样本所组成的小批量（mini-batch） B ，然后求小批量中数据样本的平均损失有关模型参数的导数（梯度），最后用此结果与预先设定的一个正数的乘积作为模型参数在本次迭代的减小量。<img src="https://img-blog.csdnimg.cn/20200214133605266.jpg" alt="在这里插入图片描述"><br>学习率:  η 代表在每次优化中，能够学习的步长的大小<br>批量大小:  B 是小批量计算中的批量大小batch size</p><p>总结一下，优化函数的有以下两个步骤：<br>(i)初始化模型参数，一般来说使用随机初始化；<br>(ii)我们在数据上迭代多次，通过在负梯度方向移动参数来更新每个参数。</p><h2 id="2-3-模型预测"><a href="#2-3-模型预测" class="headerlink" title="2.3 模型预测"></a>2.3 模型预测</h2><p>模型训练完成后，我们将模型参数 在优化算法停止时的值分别记录 。注意，这里我们得到的并不一定是最小化损失函数的最优解  ，而是对最优解的一个近似。然后，我们就可以使用学出的线性回归模型来估算训练数据集以外任意一栋面积（平方米）为 area 、房龄（年）为 age 的房屋的价格了。这里的估算也叫作模型预测、模型推断或模型测试。</p><h2 id="3-多输入通道和多输出通道"><a href="#3-多输入通道和多输出通道" class="headerlink" title="3.多输入通道和多输出通道"></a>3.多输入通道和多输出通道</h2><p>之前的输入和输出都是二维数组，但真实数据的维度经常更高。例如，彩色图像在高和宽2个维度外还有RGB（红、绿、蓝）3个颜色通道。假设彩色图像的高和宽分别是h和w（像素），那么它可以表示为一个3<em>h</em>w的多维数组，我们将大小为3的这一维称为通道（channel）维。</p><h3 id="3-1多输入通道"><a href="#3-1多输入通道" class="headerlink" title="3.1多输入通道"></a>3.1多输入通道</h3><p>卷积层的输入可以包含多个通道，图4展示了一个含2个输入通道的二维互相关计算的例子。</p><p><img src="https://img-blog.csdnimg.cn/20200218163256683.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>图4 含2个输入通道的互相关计算<br><img src="https://img-blog.csdnimg.cn/20200218163321575.png" alt="在这里插入图片描述"></p><h3 id="3-2-多输出通道"><a href="#3-2-多输出通道" class="headerlink" title="3.2 多输出通道"></a>3.2 多输出通道</h3><p><img src="https://img-blog.csdnimg.cn/20200218163348627.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h3 id="3-3-1x1卷积层"><a href="#3-3-1x1卷积层" class="headerlink" title="3.3 1x1卷积层"></a>3.3 1x1卷积层</h3><p>最后讨论形状为1x1的卷积核，我们通常称这样的卷积运算为1x1卷积，称包含这种卷积核的卷积层为1x1卷积层。图5展示了使用输入通道数为3、输出通道数为2的1x1卷积核的互相关计算。<br><img src="https://img-blog.csdnimg.cn/20200218163519224.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>图5 1x1卷积核的互相关计算。输入和输出具有相同的高和宽</p><p>1x1卷积核可在不改变高宽的情况下，调整通道数。1x1卷积核不识别高和宽维度上相邻元素构成的模式，其主要计算发生在通道维上。假设我们将通道维当作特征维，将高和宽维度上的元素当成数据样本，那么1x1卷积层的作用与全连接层等价。<br><img src="https://img-blog.csdnimg.cn/20200218163557366.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h2 id="4-池化"><a href="#4-池化" class="headerlink" title="4.池化"></a>4.池化</h2><p><strong>二维池化层</strong><br>池化层主要用于缓解卷积层对位置的过度敏感性。同卷积层一样，池化层每次对输入数据的一个固定形状窗口（又称池化窗口）中的元素计算输出，池化层直接计算池化窗口内元素的最大值或者平均值，该运算也分别叫做最大池化或平均池化。图6展示了池化窗口形状为2<em>2的最大池化。<br><img src="https://img-blog.csdnimg.cn/20200218163723803.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>图6 池化窗口形状为 2 x 2 的最大池化<br>二维平均池化的工作原理与二维最大池化类似，但将最大运算符替换成平均运算符。池化窗口形状为p</em>q的池化层称为p<em>q池化层，其中的池化运算叫作p</em>q池化。</p><p>池化层也可以在输入的高和宽两侧填充并调整窗口的移动步幅来改变输出形状。池化层填充和步幅与卷积层填充和步幅的工作机制一样。</p><p>在处理多通道输入数据时，池化层对每个输入通道分别池化，但不会像卷积层那样将各通道的结果按通道相加。这意味着池化层的输出通道数与输入通道数相等。</p><p>代码与讲解链接：<a href="https://www.kesci.com/org/boyuai/workspace/project" target="_blank" rel="noopener">添加链接描述</a></p><p><strong>习题练习：</strong><br><img src="https://img-blog.csdnimg.cn/2020021816390699.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h1 id="二、leNet"><a href="#二、leNet" class="headerlink" title="二、leNet"></a><strong>二、leNet</strong></h1><p><strong>主要内容：<br>1.leNet结构介绍</strong></p><h2 id="1-leNet结构介绍"><a href="#1-leNet结构介绍" class="headerlink" title="1.leNet结构介绍"></a>1.leNet结构介绍</h2><p>使用全连接层的局限性：</p><ul><li>图像在同一列邻近的像素在这个向量中可能相距较远。它们构成的模式可能难以被模型识别。</li><li>对于大尺寸的输入图像，使用全连接层容易导致模型过大。</li></ul><p>使用卷积层的优势：</p><ul><li>卷积层保留输入形状。</li><li>卷积层通过滑动窗口将同一卷积核与不同位置的输入重复计算，从而避免参数尺寸过大。</li></ul><p><strong>LeNet 模型</strong><br>LeNet分为卷积层块和全连接层块两个部分。<br><img src="https://img-blog.csdnimg.cn/20200218164246111.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>卷积层块里的基本单位是卷积层后接平均池化层：卷积层用来识别图像里的空间模式，如线条和物体局部，之后的平均池化层则用来降低卷积层对位置的敏感性。</p><p>卷积层块由两个这样的基本单位重复堆叠构成。在卷积层块中，每个卷积层都使用的窗口，并在输出上使用sigmoid激活函数。第一个卷积层输出通道数为6，第二个卷积层输出通道数则增加到16。</p><p>全连接层块含3个全连接层。它们的输出个数分别是120、84和10，其中10为输出的类别个数。</p><p><strong>卷积神经网络就是含卷积层的网络。 LeNet交替使用卷积层和最大池化层后接全连接层来进行图像分类。</strong></p><p>代码与讲解链接：<a href="https://www.kesci.com/org/boyuai/workspace/project" target="_blank" rel="noopener">添加链接描述</a></p><p><strong>习题练习：</strong><br><img src="https://img-blog.csdnimg.cn/20200218164433701.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h1 id="三、卷积神经网络进阶"><a href="#三、卷积神经网络进阶" class="headerlink" title="三、卷积神经网络进阶"></a><strong>三、卷积神经网络进阶</strong></h1><p><strong>主要内容：<br>1.深度卷积神经网络（AlexNet）<br>2.使用重复元素的网络（VGG）<br>3.网络中的网络（NiN）<br>4.GoogLeNet</strong></p><h2 id="1-深度卷积神经网络（AlexNet）"><a href="#1-深度卷积神经网络（AlexNet）" class="headerlink" title="1.深度卷积神经网络（AlexNet）"></a>1.深度卷积神经网络（AlexNet）</h2><p>LeNet: 在大的真实数据集上的表现并不尽如人意。<br>1.神经网络计算复杂。<br>2.还没有大量深入研究参数初始化和非凸优化算法等诸多领域。</p><p>机器学习的特征提取:手工定义的特征提取函数<br>神经网络的特征提取：通过学习得到数据的多级表征，并逐级表⽰越来越抽象的概念或模式。</p><p>神经网络发展的限制:数据、硬件。</p><h3 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a><strong>AlexNet</strong></h3><p>首次证明了学习到的特征可以超越⼿⼯设计的特征，从而⼀举打破计算机视觉研究的前状。<br><strong>特征：</strong></p><ol><li>8层变换，其中有5层卷积和2层全连接隐藏层，以及1个全连接输出层。</li><li>将sigmoid激活函数改成了更加简单的ReLU激活函数。</li><li>用Dropout来控制全连接层的模型复杂度。</li><li>引入数据增强，如翻转、裁剪和颜色变化，从而进一步扩大数据集来缓解过拟合。<br><img src="https://img-blog.csdnimg.cn/20200218164740872.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></li></ol><h2 id="2-使用重复元素的网络（VGG）"><a href="#2-使用重复元素的网络（VGG）" class="headerlink" title="2.使用重复元素的网络（VGG）"></a>2.使用重复元素的网络（VGG）</h2><p>VGG：通过重复使⽤简单的基础块来构建深度模型。<br>Block:数个相同的填充为1、窗口形状为3<em>3的卷积层,接上一个步幅为2、窗口形状为2</em>2的最大池化层。<br>卷积层保持输入的高和宽不变，而池化层则对其减半。<br><img src="https://img-blog.csdnimg.cn/20200218164840702.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h2 id="3-网络中的网络（NiN）"><a href="#3-网络中的网络（NiN）" class="headerlink" title="3.网络中的网络（NiN）"></a>3.网络中的网络（NiN）</h2><p>LeNet、AlexNet和VGG：先以由卷积层构成的模块充分抽取 空间特征，再以由全连接层构成的模块来输出分类结果。<br>NiN：串联多个由卷积层和“全连接”层构成的小网络来构建⼀个深层⽹络。<br>⽤了输出通道数等于标签类别数的NiN块，然后使用全局平均池化层对每个通道中所有元素求平均并直接用于分类。<br><img src="https://img-blog.csdnimg.cn/20200218164938331.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>1×1卷积核作用：<br>1.放缩通道数：通过控制卷积核的数量达到通道数的放缩。<br>2.增加非线性。1×1卷积核的卷积过程相当于全连接层的计算过程，并且还加入了非线性激活函数，从而可以增加网络的非线性。<br>3.计算参数少</p><h2 id="4-GoogLeNet"><a href="#4-GoogLeNet" class="headerlink" title="4.GoogLeNet"></a>4.GoogLeNet</h2><ol><li>由Inception基础块组成。</li><li>Inception块相当于⼀个有4条线路的⼦⽹络。它通过不同窗口形状的卷积层和最⼤池化层来并⾏抽取信息，并使⽤1×1卷积层减少通道数从而降低模型复杂度。</li><li>可以⾃定义的超参数是每个层的输出通道数，我们以此来控制模型复杂度。</li></ol><p><img src="https://img-blog.csdnimg.cn/20200218165047170.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><strong>GoogLeNet模型</strong><br>完整模型结构<br><img src="https://img-blog.csdnimg.cn/20200218165144802.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p>代码与讲解链接：<a href="https://www.kesci.com/org/boyuai/workspace/project" target="_blank" rel="noopener">添加链接描述</a><br>帮助理解的博客：<a href="https://blog.csdn.net/zh_ch_yu/article/details/88383196" target="_blank" rel="noopener">添加链接描述</a><br>帮助理解的博客：<a href="https://blog.csdn.net/u013679159/article/details/104209344" target="_blank" rel="noopener">添加链接描述</a><br>帮助理解的博客：<a href="https://www.cnblogs.com/yh-blog/p/10052915.html" target="_blank" rel="noopener">添加链接描述</a><br><strong>习题练习：</strong><br><img src="https://img-blog.csdnimg.cn/20200218165359326.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><strong>参考资料：</strong><br>《动手学深度学习》中文版官网教材：<a href="http://zh.gluon.ai/" target="_blank" rel="noopener">添加链接描述</a><br>PyTorch中文文档：<a href="https://pytorch-cn.readthedocs.io/zh/stable/" target="_blank" rel="noopener">添加链接描述</a></p>]]></content>
      
      
      <categories>
          
          <category> 动手学深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 卷积神经网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《动手学深度学习》笔记 Task04_机器翻译及相关技术；注意力机制与Seq2seq模型；Transformer</title>
      <link href="/2020/02/17/article4/"/>
      <url>/2020/02/17/article4/</url>
      
        <content type="html"><![CDATA[<h1 id="一、机器翻译及相关技术"><a href="#一、机器翻译及相关技术" class="headerlink" title="一、机器翻译及相关技术"></a>一、机器翻译及相关技术</h1><p><strong>主要内容：<br>1.机器翻译<br>2.编码器—解码器<br>3.Sequence to Sequence模型<br>4.束搜索</strong></p><h2 id="1-机器翻译"><a href="#1-机器翻译" class="headerlink" title="1.机器翻译"></a>1.机器翻译</h2><p>机器翻译是指将一段文本从一种语言自动翻译到另一种语言。因为一段文本序列在不同语言中的长度不一定相同，所以我们使用机器翻译为例来介绍编码器—解码器和注意力机制的应用。包括四个部分：<br>1.读取和预处理数据：将数据集清洗、转化为神经网络的输入minbatch<br>2.分词：字符串—单词组成的列表<br>3.建立字典：单词组成的列表—单词id组成的列表<br>4.载入数据集</p><h2 id="2-编码器—解码器（Encoder-Decoder）"><a href="#2-编码器—解码器（Encoder-Decoder）" class="headerlink" title="2.编码器—解码器（Encoder-Decoder）"></a>2.编码器—解码器（Encoder-Decoder）</h2><p>Encoder：输入到隐藏状态<br>Decoder：隐藏状态到输出</p><p><img src="https://img-blog.csdnimg.cn/20200218155451192.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h2 id="3-Sequence-to-Sequence模型"><a href="#3-Sequence-to-Sequence模型" class="headerlink" title="3.Sequence to Sequence模型"></a>3.Sequence to Sequence模型</h2><p><img src="https://img-blog.csdnimg.cn/2020021815561118.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h2 id="4-束搜索-Beam-Search"><a href="#4-束搜索-Beam-Search" class="headerlink" title="4.束搜索(Beam Search)"></a>4.束搜索(Beam Search)</h2><p><img src="https://img-blog.csdnimg.cn/20200218155852824.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200218155913344.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>帮助理解Beam Search的博客：<a href="https://blog.csdn.net/wdmlovekerry/article/details/80375346" target="_blank" rel="noopener">添加链接描述</a><br>代码讲解和帮助文档链接：<a href="https://www.kesci.com/org/boyuai/workspace/project" target="_blank" rel="noopener">添加链接描述</a></p><p><strong>习题练习：</strong><br><img src="https://img-blog.csdnimg.cn/20200218160030329.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h1 id="二、注意力机制与Seq2seq模型"><a href="#二、注意力机制与Seq2seq模型" class="headerlink" title="二、注意力机制与Seq2seq模型"></a>二、注意力机制与Seq2seq模型</h1><p><strong>主要内容：<br>1.注意力机制<br>2.引入注意力机制的Seq2seq模型<br>3.语言模型数据集的两种采样方法</strong></p><h2 id="1-注意力机制"><a href="#1-注意力机制" class="headerlink" title="1.注意力机制"></a>1.注意力机制</h2><p>在“编码器—解码器（seq2seq）”⼀节⾥，解码器在各个时间步依赖相同的背景变量（context vector）来获取输⼊序列信息。当编码器为循环神经⽹络时，背景变量来⾃它最终时间步的隐藏状态。将源序列输入信息以循环单位状态编码，然后将其传递给解码器以生成目标序列。然而这种结构存在着问题，尤其是RNN机制实际中存在长程梯度消失的问题，对于较长的句子，我们很难寄希望于将输入的序列转化为定长的向量而保存所有的有效信息，所以随着所需翻译句子的长度的增加，这种结构的效果会显著下降。</p><p>与此同时，解码的目标词语可能只与原输入的部分词语有关，而并不是与所有的输入有关。例如，当把“Hello world”翻译成“Bonjour le monde”时，“Hello”映射成“Bonjour”，“world”映射成“monde”。在seq2seq模型中，解码器只能隐式地从编码器的最终状态中选择相应的信息。然而，注意力机制可以将这种选择过程显式地建模。<br><img src="https://img-blog.csdnimg.cn/20200218160254622.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h3 id="1-1注意力机制框架"><a href="#1-1注意力机制框架" class="headerlink" title="1.1注意力机制框架"></a>1.1注意力机制框架</h3><p><img src="https://img-blog.csdnimg.cn/20200218160342424.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>我们使用 softmax函数 获得注意力权重：<br><img src="https://img-blog.csdnimg.cn/20200218160402441.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">不同的attetion layer的区别在于score函数的选择。</p><h3 id="1-2-点积注意力"><a href="#1-2-点积注意力" class="headerlink" title="1.2 点积注意力"></a>1.2 点积注意力</h3><p><img src="https://img-blog.csdnimg.cn/2020021816044948.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>它支持一批查询和键值对。此外，它支持作为正则化随机删除一些注意力权重。</p><h3 id="1-3-多层感知机注意力"><a href="#1-3-多层感知机注意力" class="headerlink" title="1.3 多层感知机注意力"></a>1.3 多层感知机注意力</h3><p><img src="https://img-blog.csdnimg.cn/20200218160525892.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><strong>总结：<br>注意力层显式地选择相关的信息。<br>注意层的内存由键-值对组成，因此它的输出接近于键类似于查询的值。</strong></p><h2 id="2-引入注意力机制的Seq2seq模型"><a href="#2-引入注意力机制的Seq2seq模型" class="headerlink" title="2.引入注意力机制的Seq2seq模型"></a>2.引入注意力机制的Seq2seq模型</h2><p>本节中将注意机制添加到sequence to sequence 模型中，以显式地使用权重聚合states。下图展示encoding 和decoding的模型结构，在时间步为t的时候。此刻attention layer保存着encodering看到的所有信息——即encoding的每一步输出。在decoding阶段，解码器的t时刻的隐藏状态被当作query，encoder的每个时间步的hidden states作为key和value进行attention聚合. Attetion model的输出当作成上下文信息context vector，并与解码器输入Dt拼接起来一起送到解码器：<br><img src="https://img-blog.csdnimg.cn/20200218160642688.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>下图展示了seq2seq机制的所以层的关系，下面展示了encoder和decoder的layer结构<br><img src="https://img-blog.csdnimg.cn/20200218160659231.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><strong>解码器</strong><br>由于带有注意机制的seq2seq的编码器与之前章节中的Seq2SeqEncoder相同，所以在此处我们只关注解码器。我们添加了一个MLP注意层(MLPAttention)，它的隐藏大小与解码器中的LSTM层相同。然后我们通过从编码器传递三个参数来初始化解码器的状态:</p><ul><li>the encoder outputs of all timesteps：encoder输出的各个状态，被用于attetion layer的memory部分，有相同的key和values</li><li>the hidden state of the encoder’s final timestep：编码器最后一个时间步的隐藏状态，被用于初始化decoder 的hidden state</li><li>the encoder valid length: 编码器的有效长度，借此，注意层不会考虑编码器输出中的填充标记（Paddings）<br>在解码的每个时间步，我们使用解码器的最后一个RNN层的输出作为注意层的query。然后，将注意力模型的输出与输入嵌入向量连接起来，输入到RNN层。虽然RNN层隐藏状态也包含来自解码器的历史信息，但是attention model的输出显式地选择了enc_valid_len以内的编码器输出，这样attention机制就会尽可能排除其他不相关的信息。</li></ul><p>代码和帮助理解的文档链接：<a href="https://www.kesci.com/org/boyuai/workspace/project" target="_blank" rel="noopener">添加链接描述</a></p><p>习题练习：<br><img src="https://img-blog.csdnimg.cn/20200218160912289.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h1 id="三、Transformer"><a href="#三、Transformer" class="headerlink" title="三、Transformer"></a>三、Transformer</h1><p><strong>主要内容：<br>1.Transformer的介绍<br>2.编码器和解码器</strong></p><h2 id="1-Transformer的介绍"><a href="#1-Transformer的介绍" class="headerlink" title="1.Transformer的介绍"></a>1.Transformer的介绍</h2><p>CNNs 易于并行化，却不适合捕捉变长序列内的依赖关系。<br>RNNs 适合捕捉长距离变长序列的依赖，但是却难以实现并行化处理序列。<br>为了整合CNN和RNN的优势，[Vaswani et al., 2017] 创新性地使用注意力机制设计了Transformer模型。该模型利用attention机制实现了并行化捕捉序列依赖，并且同时处理序列的每个位置的tokens，上述优势使得Transformer模型在性能优异的同时大大减少了训练时间。<br>Transformer同样基于编码器-解码器架构，其区别主要在于以下三点：</p><ol><li>Transformer blocks：将seq2seq模型重的循环网络替换为了Transformer Blocks，该模块包含一个多头注意力层（Multi-head Attention Layers）以及两个position-wise feed-forward networks（FFN）。对于解码器来说，另一个多头注意力层被用于接受编码器的隐藏状态。</li><li>Add and norm：多头注意力层和前馈网络的输出被送到两个“add and norm”层进行处理，该层包含残差结构以及</li><li>Position encoding：由于自注意力层并没有区分元素的顺序，所以一个位置编码层被用于向序列元素里添加位置信息。<br><img src="https://img-blog.csdnimg.cn/20200218161233812.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></li></ol><h3 id="1-1多头注意力层"><a href="#1-1多头注意力层" class="headerlink" title="1.1多头注意力层"></a>1.1多头注意力层</h3><p>在我们讨论多头注意力层之前，先来迅速理解以下自注意力（self-attention）的结构。自注意力模型是一个正规的注意力模型，序列的每一个元素对应的key，value，query是完全一致的。如图10.3.2 自注意力输出了一个与输入长度相同的表征序列，与循环神经网络相比，自注意力对每个元素输出的计算是并行的，所以我们可以高效的实现这个模块。<br><img src="https://img-blog.csdnimg.cn/20200218161302650.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>多头注意力层包含h个并行的自注意力层，每一个这种层被成为一个head。对每个头来说，在进行注意力计算之前，我们会将query、key和value用三个现行层进行映射，这h个注意力头的输出将会被拼接之后输入最后一个线性层进行整合。<br><img src="https://img-blog.csdnimg.cn/20200218161345420.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h3 id="1-2基于位置的前馈网络"><a href="#1-2基于位置的前馈网络" class="headerlink" title="1.2基于位置的前馈网络"></a>1.2基于位置的前馈网络</h3><p>Transformer 模块另一个非常重要的部分就是基于位置的前馈网络（FFN），它接受一个形状为（batch_size，seq_length, feature_size）的三维张量。Position-wise FFN由两个全连接层组成，他们作用在最后一维上。因为序列的每个位置的状态都会被单独地更新，所以我们称他为position-wise，这等效于一个1x1的卷积。</p><h3 id="1-3-Add-and-Norm"><a href="#1-3-Add-and-Norm" class="headerlink" title="1.3 Add and Norm"></a>1.3 Add and Norm</h3><p>Transformer还有一个重要的相加归一化层，它可以平滑地整合输入和其他层的输出，因此我们在每个多头注意力层和FFN层后面都添加一个含残差连接的Layer Norm层。层归一化可以防止层内的数值变化过大，从而有利于加快训练速度并且提高泛化性能。</p><h3 id="1-4-位置编码"><a href="#1-4-位置编码" class="headerlink" title="1.4 位置编码"></a>1.4 位置编码</h3><p>与循环神经网络不同，无论是多头注意力网络还是前馈神经网络都是独立地对每个位置的元素进行更新，这种特性帮助我们实现了高效的并行，却丢失了重要的序列顺序的信息。为了更好的捕捉序列信息，Transformer模型引入了位置编码去保持输入序列元素的位置。<br><img src="https://img-blog.csdnimg.cn/20200218161540496.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h2 id="2-编码器和解码器"><a href="#2-编码器和解码器" class="headerlink" title="2.编码器和解码器"></a>2.编码器和解码器</h2><h3 id="2-1-编码器"><a href="#2-1-编码器" class="headerlink" title="2.1 编码器"></a>2.1 编码器</h3><p>编码器包含一个多头注意力层，一个position-wise FFN，和两个 Add and Norm层。对于attention模型以及FFN模型，我们的输出维度都是与embedding维度一致的，这也是由于残差连接天生的特性导致的，因为我们要将前一层的输出与原始输入相加并归一化。</p><h3 id="2-2-解码器"><a href="#2-2-解码器" class="headerlink" title="2.2 解码器"></a>2.2 解码器</h3><p>Transformer 模型的解码器与编码器结构类似，然而，除了之前介绍的几个模块之外，编码器部分有另一个子模块。该模块也是多头注意力层，接受编码器的输出作为key和value，decoder的状态作为query。与编码器部分相类似，解码器同样是使用了add and norm机制，用残差和层归一化将各个子层的输出相连。<br><img src="https://img-blog.csdnimg.cn/20200218161747723.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>帮助理解Transformer的博客：<a href="https://www.jianshu.com/p/e7d8caa13b21" target="_blank" rel="noopener">添加链接描述</a><br>代码和解释帮助文档：<a href="https://www.kesci.com/org/boyuai/project/5e42c3ad5f2816002ce979b0" target="_blank" rel="noopener">添加链接描述</a></p><p><strong>习题练习：</strong><br><img src="https://img-blog.csdnimg.cn/20200218162040504.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p><strong>参考资料</strong></p><p>《动手学深度学习》中文版官网教材：<a href="http://zh.gluon.ai/" target="_blank" rel="noopener">添加链接描述</a><br>PyTorch中文文档：<a href="https://pytorch-cn.readthedocs.io/zh/stable/" target="_blank" rel="noopener">添加链接描述</a></p>]]></content>
      
      
      <categories>
          
          <category> 动手学深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器翻译 </tag>
            
            <tag> 注意力机制 </tag>
            
            <tag> Seq2seq模型 </tag>
            
            <tag> Transformer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《动手学深度学习》笔记 Task03_过拟合、欠拟合及其解决方案；梯度消失、梯度爆炸；循环神经网络进阶</title>
      <link href="/2020/02/16/article3/"/>
      <url>/2020/02/16/article3/</url>
      
        <content type="html"><![CDATA[<h1 id="一、过拟合、欠拟合及其解决方案"><a href="#一、过拟合、欠拟合及其解决方案" class="headerlink" title="一、过拟合、欠拟合及其解决方案"></a><strong>一、过拟合、欠拟合及其解决方案</strong></h1><p><strong>主要内容：<br>1.模型选择、过拟合和欠拟合<br>2.权重衰减<br>3.丢弃法</strong></p><h2 id="1-模型选择、过拟合和欠拟合"><a href="#1-模型选择、过拟合和欠拟合" class="headerlink" title="1.模型选择、过拟合和欠拟合"></a>1.模型选择、过拟合和欠拟合</h2><h3 id="1-1-训练误差和泛化误差"><a href="#1-1-训练误差和泛化误差" class="headerlink" title="1.1 训练误差和泛化误差"></a>1.1 训练误差和泛化误差</h3><p>在解释上述现象之前，我们需要区分训练误差（training error）和泛化误差（generalization error）。<br><strong>训练误差（training error）：指模型在训练数据集上表现出的误差。</strong><br><strong>泛化误差（generalization error）：指模型在任意一个测试数据样本上表现出的误差的期望，并常常通过测试数据集上的误差来近似。</strong><br>计算训练误差和泛化误差可以使用之前介绍过的损失函数，例如线性回归用到的平方损失函数和softmax回归用到的交叉熵损失函数。</p><p>举例理解：以高考为例来直观地解释训练误差和泛化误差这两个概念。训练误差可以认为是做往年高考试题（训练题）时的错误率，泛化误差则可以通过真正参加高考（测试题）时的答题错误率来近似。假设训练题和测试题都随机采样于一个未知的依照相同考纲的巨大试题库。如果让一名未学习中学知识的小学生去答题，那么测试题和训练题的答题错误率可能很相近。但如果换成一名反复练习训练题的高三备考生答题，即使在训练题上做到了错误率为0，也不代表真实的高考成绩会如此。</p><p>在机器学习里，我们通常假设训练数据集（训练题）和测试数据集（测试题）里的每一个样本都是从同一个概率分布中相互独立地生成的。基于该独立同分布假设，给定任意一个机器学习模型（含参数），它的训练误差的期望和泛化误差都是一样的。例如，如果我们将模型参数设成随机值（小学生），那么训练误差和泛化误差会非常相近。但我们从前面几节中已经了解到，模型的参数是通过在训练数据集上训练模型而学习出的，参数的选择依据了最小化训练误差（高三备考生）。所以，训练误差的期望小于或等于泛化误差。也就是说，一般情况下，由训练数据集学到的模型参数会使模型在训练数据集上的表现优于或等于在测试数据集上的表现。由于无法从训练误差估计泛化误差，一味地降低训练误差并不意味着泛化误差一定会降低。</p><p><strong>机器学习模型应关注降低泛化误差。</strong></p><h3 id="1-2-模型选择"><a href="#1-2-模型选择" class="headerlink" title="1.2 模型选择"></a>1.2 模型选择</h3><p>在机器学习中，通常需要评估若干候选模型的表现并从中选择模型。这一过程称为模型选择（model selection）。可供选择的候选模型可以是有着不同超参数的同类模型。</p><h4 id="1-2-1-验证数据集"><a href="#1-2-1-验证数据集" class="headerlink" title="1.2.1 验证数据集"></a>1.2.1 验证数据集</h4><p>严格意义上讲，测试集只能在所有超参数和模型参数选定后使用一次。不可以使用测试数据选择模型，如调参。由于无法从训练误差估计泛化误差，因此也不应只依赖训练数据选择模型。鉴于此，我们可以预留一部分在训练数据集和测试数据集以外的数据来进行模型选择。这部分数据被称为验证数据集，简称验证集（validation set）。例如，我们可以从给定的训练集中随机选取一小部分作为验证集，而将剩余部分作为真正的训练集。</p><h4 id="1-2-2-K折交叉验证"><a href="#1-2-2-K折交叉验证" class="headerlink" title="1.2.2 K折交叉验证"></a>1.2.2 K折交叉验证</h4><p>由于验证数据集不参与模型训练，当训练数据不够用时，预留大量的验证数据显得太奢侈。一种改善的方法是K折交叉验证（K-fold cross-validation）。在K折交叉验证中，我们把原始训练数据集分割成K个不重合的子数据集，然后我们做K次模型训练和验证。每一次，我们使用一个子数据集验证模型，并使用其他K-1个子数据集来训练模型。在这K次训练和验证中，每次用来验证模型的子数据集都不同。最后，我们对这K次训练误差和验证误差分别求平均。</p><h3 id="1-3-过拟合和欠拟合"><a href="#1-3-过拟合和欠拟合" class="headerlink" title="1.3 过拟合和欠拟合"></a>1.3 过拟合和欠拟合</h3><p>接下来，我们将探究模型训练中经常出现的两类典型问题：<br>一类是模型无法得到较低的训练误差，我们将这一现象称作<strong>欠拟合（underfitting）</strong>；<br>另一类是模型的训练误差远小于它在测试数据集上的误差，我们称该现象为<strong>过拟合（overfitting）</strong>。<br>在实践中，我们要尽可能同时应对欠拟合和过拟合。虽然有很多因素可能导致这两种拟合问题，在这里我们重点讨论两个因素：模型复杂度和训练数据集大小。</p><h4 id="1-3-1模型复杂度"><a href="#1-3-1模型复杂度" class="headerlink" title="1.3.1模型复杂度"></a>1.3.1模型复杂度</h4><p>为了解释模型复杂度，我们以多项式函数拟合为例。给定一个由标量数据特征x和对应的标量标签y组成的训练数据集，多项式函数拟合的目标是找一个K阶多项式函数</p><p><img src="https://img-blog.csdnimg.cn/20200218150232283.png" alt="在这里插入图片描述"><br>来近似y 。在上式中，wk是模型的权重参数，b是偏差参数。与线性回归相同，多项式函数拟合也使用平方损失函数。特别地，一阶多项式函数拟合又叫线性函数拟合。</p><p>因为高阶多项式函数模型参数更多，模型函数的选择空间更大，所以高阶多项式函数比低阶多项式函数的复杂度更高。因此，高阶多项式函数比低阶多项式函数更容易在相同的训练数据集上得到更低的训练误差。给定训练数据集，模型复杂度和误差之间的关系通常如图所示。给定训练数据集，如果模型的复杂度过低，很容易出现欠拟合；如果模型复杂度过高，很容易出现过拟合。应对欠拟合和过拟合的一个办法是针对数据集选择合适复杂度的模型。<br><img src="https://img-blog.csdnimg.cn/20200218150410812.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h4 id="1-3-2训练数据集大小"><a href="#1-3-2训练数据集大小" class="headerlink" title="1.3.2训练数据集大小"></a>1.3.2训练数据集大小</h4><p>影响欠拟合和过拟合的另一个重要因素是训练数据集的大小。一般来说，如果训练数据集中样本数过少，特别是比模型参数数量（按元素计）更少时，过拟合更容易发生。此外，泛化误差不会随训练数据集里样本数量增加而增大。因此，在计算资源允许的范围之内，我们通常希望训练数据集大一些，特别是在模型复杂度较高时，例如层数较多的深度学习模型。<br>代码与讲解链接：<a href="https://www.kesci.com/org/boyuai/workspace/project" target="_blank" rel="noopener">添加链接描述</a><br>帮助理解的博客链接：<a href="https://blog.csdn.net/dyx810601/article/details/82141789" target="_blank" rel="noopener">添加链接描述</a></p><h2 id="2-权重衰减"><a href="#2-权重衰减" class="headerlink" title="2.权重衰减"></a>2.权重衰减</h2><h2 id="2-1-方法"><a href="#2-1-方法" class="headerlink" title="# 2.1 方法"></a># 2.1 方法</h2><p>权重衰减等价于 L2范数正则化（regularization）。正则化通过为模型损失函数添加惩罚项使学出的模型参数值较小，是应对过拟合的常用手段。<br><img src="https://img-blog.csdnimg.cn/20200214133203357.jpg" alt="在这里插入图片描述"></p><h2 id="2-2-L2-范数正则化（regularization）"><a href="#2-2-L2-范数正则化（regularization）" class="headerlink" title="# 2.2 L2 范数正则化（regularization）"></a># 2.2 L2 范数正则化（regularization）</h2><p>L2范数正则化在模型原损失函数基础上添加L2范数惩罚项，从而得到训练所需要最小化的函数。L2范数惩罚项指的是模型权重参数每个元素的平方和与一个正的常数的乘积。以线性回归中的线性回归损失函数为例<br><img src="https://img-blog.csdnimg.cn/20200218151100774.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h2 id="3-丢弃法"><a href="#3-丢弃法" class="headerlink" title="3.丢弃法"></a>3.丢弃法</h2><p>深度学习模型常常使用丢弃法（dropout） 来应对过拟合问题。<br><img src="https://img-blog.csdnimg.cn/20200218151730726.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>代码与讲解链接：<a href="https://www.kesci.com/org/boyuai/workspace/project" target="_blank" rel="noopener">添加链接描述</a></p><p><strong>习题练习：</strong><br><img src="https://img-blog.csdnimg.cn/20200218151946735.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h1 id="二、梯度消失、梯度爆炸"><a href="#二、梯度消失、梯度爆炸" class="headerlink" title="二、梯度消失、梯度爆炸"></a><strong>二、梯度消失、梯度爆炸</strong></h1><p><strong>主要内容：<br>1.梯度消失和梯度爆炸<br>2.考虑到环境因素的其他问题</strong></p><h2 id="1-梯度消失和梯度爆炸"><a href="#1-梯度消失和梯度爆炸" class="headerlink" title="1.梯度消失和梯度爆炸"></a>1.梯度消失和梯度爆炸</h2><p>深度模型有关数值稳定性的典型问题是消失（vanishing）和爆炸（explosion）。<br><img src="https://img-blog.csdnimg.cn/2020021815240691.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h3 id="1-1随机初始化模型参数"><a href="#1-1随机初始化模型参数" class="headerlink" title="1.1随机初始化模型参数"></a>1.1随机初始化模型参数</h3><p>在神经网络中，通常需要随机初始化模型参数。下面我们来解释这样做的原因。<br>回顾多层感知机一节描述的多层感知机。为了方便解释，假设输出层只保留一个输出单元o1（删去o2和o3以及指向它们的箭头），且隐藏层使用相同的激活函数。如果将每个隐藏单元的参数都初始化为相等的值，那么在正向传播时每个隐藏单元将根据相同的输入计算出相同的值，并传递至输出层。在反向传播中，每个隐藏单元的参数梯度值相等。因此，这些参数在使用基于梯度的优化算法迭代后值依然相等。之后的迭代也是如此。在这种情况下，无论隐藏单元有多少，隐藏层本质上只有1个隐藏单元在发挥作用。因此，正如在前面的实验中所做的那样，我们通常将神经网络的模型参数，特别是权重参数，进行随机初始化。<br><img src="https://img-blog.csdnimg.cn/20200218152550458.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h4 id="1-1-1-PyTorch的默认随机初始化"><a href="#1-1-1-PyTorch的默认随机初始化" class="headerlink" title="1.1.1 PyTorch的默认随机初始化"></a>1.1.1 PyTorch的默认随机初始化</h4><p>随机初始化模型参数的方法有很多。在线性回归的简洁实现中，我们使用torch.nn.init.normal_()使模型net的权重参数采用正态分布的随机初始化方式。不过，PyTorch中nn.Module的模块参数都采取了较为合理的初始化策略（不同类型的layer具体采样的哪一种初始化方法的可参考源代码），因此一般不用我们考虑。</p><h4 id="1-1-2-Xavier随机初始化"><a href="#1-1-2-Xavier随机初始化" class="headerlink" title="1.1.2 Xavier随机初始化"></a>1.1.2 Xavier随机初始化</h4><p>还有一种比较常用的随机初始化方法叫作Xavier随机初始化。 假设某全连接层的输入个数为a，输出个数为b，Xavier随机初始化将使该层中权重参数的每个元素都随机采样于均匀分布<br><img src="https://img-blog.csdnimg.cn/20200218152742220.png" alt="在这里插入图片描述"><br>它的设计主要考虑到，模型参数初始化后，每层输出的方差不该受该层输入个数影响，且每层梯度的方差也不该受该层输出个数影响。</p><h2 id="2-考虑环境因素"><a href="#2-考虑环境因素" class="headerlink" title="2.考虑环境因素"></a>2.考虑环境因素</h2><h3 id="2-1-协变量偏移"><a href="#2-1-协变量偏移" class="headerlink" title="2.1 协变量偏移"></a>2.1 协变量偏移</h3><p>这里我们假设，虽然输入的分布可能随时间而改变，但是标记函数，即条件分布P（y∣x）不会改变。虽然这个问题容易理解，但在实践中也容易忽视。统计学家称这种协变量变化是因为问题的根源在于特征分布的变化（即协变量的变化）。数学上，我们可以说P（x）改变了，但P（y∣x）保持不变。尽管它的有用性并不局限于此，当我们认为x导致y时，协变量移位通常是正确的假设。</p><h3 id="2-2-标签偏移"><a href="#2-2-标签偏移" class="headerlink" title="2.2 标签偏移"></a>2.2 标签偏移</h3><p>当我们认为导致偏移的是标签P（y）上的边缘分布的变化，但类条件分布是不变的P（x∣y）时，就会出现相反的问题。当我们认为y导致x时，标签偏移是一个合理的假设。例如，通常我们希望根据其表现来预测诊断结果。在这种情况下，我们认为诊断引起的表现，即疾病引起的症状。有时标签偏移和协变量移位假设可以同时成立。例如，当真正的标签函数是确定的和不变的，那么协变量偏移将始终保持，包括如果标签偏移也保持。有趣的是，当我们期望标签偏移和协变量偏移保持时，使用来自标签偏移假设的方法通常是有利的。这是因为这些方法倾向于操作看起来像标签的对象，这（在深度学习中）与处理看起来像输入的对象（在深度学习中）相比相对容易一些。<br>病因（要预测的诊断结果）导致 症状（观察到的结果）。<br>训练数据集，数据很少只包含流感p(y)的样本。<br>而测试数据集有流感p(y)和流感q(y)，其中不变的是流感症状p(x|y)。</p><h3 id="2-3-概念偏移"><a href="#2-3-概念偏移" class="headerlink" title="2.3 概念偏移"></a>2.3 概念偏移</h3><p>如果我们要建立一个机器翻译系统，分布P（y∣x）可能因我们的位置而异。这个问题很难发现。另一个可取之处是P（y∣x）通常只是逐渐变化。</p><p>代码与讲解链接：<a href="https://www.kesci.com/org/boyuai/workspace/project" target="_blank" rel="noopener">添加链接描述</a></p><p><strong>习题练习：</strong><br><img src="https://img-blog.csdnimg.cn/20200218154648931.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h1 id="三、循环神经网络进阶"><a href="#三、循环神经网络进阶" class="headerlink" title="三、循环神经网络进阶"></a><strong>三、循环神经网络进阶</strong></h1><p><strong>主要内容：<br>1.门控循环单元（GRU）<br>2.长短期记忆（LSTM）<br>3.深度循环神经网络<br>4.双向循环神经网络</strong></p><h2 id="1-门控循环单元（GRU）"><a href="#1-门控循环单元（GRU）" class="headerlink" title="1.门控循环单元（GRU）"></a>1.门控循环单元（GRU）</h2><p>它引入了重置门（reset gate）和更新门（update gate）的概念，从而修改了循环神经网络中隐藏状态的计算方式。<br><img src="https://img-blog.csdnimg.cn/2020021815365031.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200218153703226.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>我们对门控循环单元的设计稍作总结：<br><strong>重置门有助于捕捉时间序列里短期的依赖关系；</strong><br><strong>更新门有助于捕捉时间序列里长期的依赖关系。</strong></p><h2 id="2-长短期记忆（LSTM）"><a href="#2-长短期记忆（LSTM）" class="headerlink" title="2.长短期记忆（LSTM）"></a>2.长短期记忆（LSTM）</h2><p>另一种常用的门控循环神经网络：长短期记忆（long short-term memory，LSTM）。它比门控循环单元的结构稍微复杂一点。LSTM 中引入了3个门，即输入门（input gate）、遗忘门（forget gate）和输出门（output gate），以及与隐藏状态形状相同的记忆细胞（某些文献把记忆细胞当成一种特殊的隐藏状态），从而记录额外的信息。<br><img src="https://img-blog.csdnimg.cn/20200218153912566.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>遗忘门:控制上一时间步的记忆细胞 输入门:控制当前时间步的输入<br>输出门:控制从记忆细胞到隐藏状态<br>记忆细胞：⼀种特殊的隐藏状态的信息的流动<br>注意：<br>长短期记忆的隐藏层输出包括隐藏状态和记忆细胞。只有隐藏状态会传递到输出层。<br>长短期记忆的输入门、遗忘门和输出门可以控制信息的流动。<br>长短期记忆可以应对循环神经网络中的梯度衰减问题，并更好地捕捉时间序列中时间步距离较大的依赖关系。</p><h2 id="3-深度循环神经网络"><a href="#3-深度循环神经网络" class="headerlink" title="3.深度循环神经网络"></a>3.深度循环神经网络</h2><p>在深度学习应用里，我们通常会用到含有多个隐藏层的循环神经网络，也称作深度循环神经网络。<br><img src="https://img-blog.csdnimg.cn/20200218154051838.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200218154133516.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>在深度循环神经网络中，隐藏状态的信息不断传递至当前层的下一时间步和当前时间步的下一层。</p><h2 id="4-双向循环神经网络"><a href="#4-双向循环神经网络" class="headerlink" title="4.双向循环神经网络"></a>4.双向循环神经网络</h2><p>之前介绍的循环神经网络模型都是假设当前时间步是由前面的较早时间步的序列决定的，因此它们都将信息通过隐藏状态从前往后传递。有时候，当前时间步也可能由后面时间步决定。例如，当我们写下一个句子时，可能会根据句子后面的词来修改句子前面的用词。双向循环神经网络通过增加从后往前传递信息的隐藏层来更灵活地处理这类信息。<br><img src="https://img-blog.csdnimg.cn/20200218154226936.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200218154153564.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>双向循环神经网络在每个时间步的隐藏状态同时取决于该时间步之前和之后的子序列（包括当前时间步的输入）。</p><p>代码与讲解链接：<a href="https://www.kesci.com/org/boyuai/workspace/project" target="_blank" rel="noopener">添加链接描述</a></p><p><strong>习题练习：</strong><br><img src="https://img-blog.csdnimg.cn/20200218154528762.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p><strong>参考资料：</strong><br>《动手学深度学习》中文版官网教材：<a href="http://zh.gluon.ai/" target="_blank" rel="noopener">添加链接描述</a><br>PyTorch中文文档：<a href="https://pytorch-cn.readthedocs.io/zh/stable/" target="_blank" rel="noopener">添加链接描述</a></p>]]></content>
      
      
      <categories>
          
          <category> 动手学深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 过拟合 </tag>
            
            <tag> 欠拟合 </tag>
            
            <tag> 梯度消失 </tag>
            
            <tag> 梯度爆炸 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《动手学深度学习》笔记 Task01_线性回归；Softmax与分类模型、多层感知机</title>
      <link href="/2020/02/13/article1/"/>
      <url>/2020/02/13/article1/</url>
      
        <content type="html"><![CDATA[<h1 id="一、线性回归"><a href="#一、线性回归" class="headerlink" title="一、线性回归"></a><strong>一、线性回归</strong></h1><p><strong>主要内容：<br>1.线性回归的解释<br>2.线性回归模型的基本要素<br>3.线性回归模型的两种实现方式</strong></p><h2 id="1-线性回归的解释"><a href="#1-线性回归的解释" class="headerlink" title="1.线性回归的解释"></a>1.线性回归的解释</h2><p>线性回归，就是能够用一个直线较为精确地描述数据之间的关系。这样当出现新的数据的时候，就能够预测出一个简单的值。线性回归中最常见的就是房价的问题。一直存在很多房屋面积和房价的数据，如下图所示：<br><img src="https://img-blog.csdnimg.cn/20200214132232134.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>在这种情况下，就可以利用线性回归构造出一条直线来近似地描述放假与房屋面积之间的关系，从而就可以根据房屋面积推测出房价。<br><em>线性回归输出是一个连续值，因此适用于回归问题</em>。回归问题在实际中很常见，如预测房屋价格、气温、销售额等连续值的问题。与回归问题不同，分类问题中模型的最终输出是一个离散值。我们所说的图像分类、垃圾邮件识别、疾病检测等输出为离散值的问题都属于分类问题的范畴。softmax回归则适用于分类问题。<br>由于==线性回归和softmax回归都是单层神经网络==，它们涉及的概念和技术同样适用于大多数的深度学习模型。</p><h2 id="2-线性回归模型的基本要素"><a href="#2-线性回归模型的基本要素" class="headerlink" title="2.线性回归模型的基本要素"></a>2.线性回归模型的基本要素</h2><h2 id="2-1-模型"><a href="#2-1-模型" class="headerlink" title="2.1 模型"></a>2.1 模型</h2><p>为了简单起见，这里我们假设价格只取决于房屋状况的两个因素，即面积（平方米）和房龄（年）。接下来我们希望探索价格与这两个因素的具体关系。线性回归假设输出与各个输入之间是线性关系:<br><img src="https://img-blog.csdnimg.cn/20200214133203357.jpg" alt="在这里插入图片描述"></p><h2 id="2-2-模型训练"><a href="#2-2-模型训练" class="headerlink" title="2.2 模型训练"></a>2.2 模型训练</h2><p>接下来我们需要通过数据来寻找特定的模型参数值，使模型在数据上的误差尽可能小。这个过程叫作模型训练（model training）。下面我们介绍模型训练所涉及的3个要素。</p><h3 id="2-2-1-数据集"><a href="#2-2-1-数据集" class="headerlink" title="2.2.1 数据集"></a>2.2.1 数据集</h3><p>我们通常收集一系列的真实数据，例如多栋房屋的真实售出价格和它们对应的面积和房龄。我们希望在这个数据上面寻找模型参数来使模型的预测价格与真实价格的误差最小。在机器学习术语里，该数据集被称为训练数据集（training data set）或训练集（training set），一栋房屋被称为一个样本（sample），其真实售出价格叫作标签（label），用来预测标签的两个因素叫作特征（feature）。特征用来表征样本的特点。</p><h3 id="2-2-2-损失函数"><a href="#2-2-2-损失函数" class="headerlink" title="2.2.2 损失函数"></a>2.2.2 损失函数</h3><p>模型训练中，我们需要衡量价格预测值与真实值之间的误差。通常我们会选取一个非负数作为误差，且数值越小表示误差越小。一个常用的选择是平方函数。 它在评估索引为  i  的样本误差的表达式为<br><img src="https://img-blog.csdnimg.cn/2020021413334554.jpg" alt="在这里插入图片描述"></p><h3 id="2-2-3-优化函数-随机梯度下降"><a href="#2-2-3-优化函数-随机梯度下降" class="headerlink" title="2.2.3 优化函数 - 随机梯度下降"></a>2.2.3 优化函数 - 随机梯度下降</h3><p>当模型和损失函数形式较为简单时，上面的误差最小化问题的解可以直接用公式表达出来。这类解叫作解析解（analytical solution）。本节使用的线性回归和平方误差刚好属于这个范畴。然而，大多数深度学习模型并没有解析解，只能通过优化算法有限次迭代模型参数来尽可能降低损失函数的值。这类解叫作数值解（numerical solution）。</p><p>在求数值解的优化算法中，小批量随机梯度下降（mini-batch stochastic gradient descent）在深度学习中被广泛使用。它的算法很简单：先选取一组模型参数的初始值，如随机选取；接下来对参数进行多次迭代，使每次迭代都可能降低损失函数的值。在每次迭代中，先随机均匀采样一个由固定数目训练数据样本所组成的小批量（mini-batch） B ，然后求小批量中数据样本的平均损失有关模型参数的导数（梯度），最后用此结果与预先设定的一个正数的乘积作为模型参数在本次迭代的减小量。<img src="https://img-blog.csdnimg.cn/20200214133605266.jpg" alt="在这里插入图片描述"><br>学习率:  η 代表在每次优化中，能够学习的步长的大小<br>批量大小:  B 是小批量计算中的批量大小batch size</p><p>总结一下，优化函数的有以下两个步骤：<br>(i)初始化模型参数，一般来说使用随机初始化；<br>(ii)我们在数据上迭代多次，通过在负梯度方向移动参数来更新每个参数。</p><h2 id="2-3-模型预测"><a href="#2-3-模型预测" class="headerlink" title="2.3 模型预测"></a>2.3 模型预测</h2><p>模型训练完成后，我们将模型参数 在优化算法停止时的值分别记录 。注意，这里我们得到的并不一定是最小化损失函数的最优解  ，而是对最优解的一个近似。然后，我们就可以使用学出的线性回归模型来估算训练数据集以外任意一栋面积（平方米）为 area 、房龄（年）为 age 的房屋的价格了。这里的估算也叫作模型预测、模型推断或模型测试。</p><h2 id="3-线性回归模型的两种实现方式"><a href="#3-线性回归模型的两种实现方式" class="headerlink" title="3.线性回归模型的两种实现方式"></a>3.线性回归模型的两种实现方式</h2><p>方式一：从零开始的实现（推荐用来学习），能够更好的理解模型和神经网络底层的原理<br>方式二：使用pytorch的简洁实现，能够更加快速地完成模型的设计与实现<br>代码与讲解链接：<a href="https://www.kesci.com/org/boyuai/workspace/project" target="_blank" rel="noopener">添加链接描述</a></p><p><strong>习题练习：</strong><br><img src="https://img-blog.csdnimg.cn/20200214135309137.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h1 id="二、Softmax与分类模型"><a href="#二、Softmax与分类模型" class="headerlink" title="二、Softmax与分类模型"></a><strong>二、Softmax与分类模型</strong></h1><p>线性回归模型适用于输出为连续值的情景。在另一类情景中，模型输出可以是一个像图像类别这样的离散值。对于这样的离散值预测问题，我们可以使用诸如softmax回归在内的分类模型。和线性回归不同，softmax回归的输出单元从一个变成了多个，且引入了softmax运算使输出更适合离散值的预测和训练。本节以softmax回归模型为例，介绍神经网络中的分类模型。</p><p><strong>主要内容：<br>1.softmax回归的基本概念<br>2.softmax回归模型的两种实现，实现一个对Fashion-MNIST训练集中的图像数据进行分类的模型</strong></p><h2 id="1-softmax回归的基本概念"><a href="#1-softmax回归的基本概念" class="headerlink" title="1.softmax回归的基本概念"></a>1.softmax回归的基本概念</h2><h3 id="1-1分类问题"><a href="#1-1分类问题" class="headerlink" title="1.1分类问题"></a>1.1分类问题</h3><p>一个简单的图像分类问题，输入图像的高和宽均为2像素，色彩为灰度。<br>图像中的4像素分别记为x1, x2, x3, x4。<br>假设真实标签为狗、猫或者鸡，这些标签对应的离散值为y1, y2, y3。<br>我们通常使用离散的数值来表示类别，例如y1=1, y2=2, y3=3。</p><h3 id="1-2权重矢量"><a href="#1-2权重矢量" class="headerlink" title="1.2权重矢量"></a>1.2权重矢量</h3><p><img src="https://img-blog.csdnimg.cn/20200214141026943.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h3 id="1-3神经网络图"><a href="#1-3神经网络图" class="headerlink" title="1.3神经网络图"></a>1.3神经网络图</h3><p>下图用神经网络图描绘了上面的计算。softmax回归同线性回归一样，也是一个单层神经网络。由于每个输出o1, o2, o3的计算都要依赖于所有的输入x1, x2, x3, x4，softmax回归的输出层也是一个全连接层。<br><img src="https://img-blog.csdnimg.cn/20200214141157927.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200214141421164.jpg" alt="在这里插入图片描述"></p><h3 id="1-4输出问题"><a href="#1-4输出问题" class="headerlink" title="1.4输出问题"></a>1.4输出问题</h3><p>直接使用输出层的输出有两个问题：<br>1.一方面，由于输出层的输出值的范围不确定，我们难以直观上判断这些值的意义。例如，刚才举的例子中的输出值10表示“很置信”图像类别为猫，因为该输出值是其他两类的输出值的100倍。但如果o1=o3=10^3，那么输出值10却又表示图像类别为猫的概率很低。<br>2.另一方面，由于真实标签是离散值，这些离散值与不确定范围的输出值之间的误差难以衡量。<br>softmax运算符（softmax operator）解决了以上两个问题。它通过下式将输出值变换成值为正且和为1的概率分布：<img src="https://img-blog.csdnimg.cn/20200214141611912.jpg" alt="在这里插入图片描述"><br>其中<br><img src="https://img-blog.csdnimg.cn/20200214141706632.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>因此softmax运算不改变预测类别输出。</p><h3 id="1-4计算效率"><a href="#1-4计算效率" class="headerlink" title="1.4计算效率"></a>1.4计算效率</h3><h4 id="1-4-1单样本矢量计算表达式"><a href="#1-4-1单样本矢量计算表达式" class="headerlink" title="1.4.1单样本矢量计算表达式"></a>1.4.1单样本矢量计算表达式</h4><p>为了提高计算效率，我们可以将单样本分类通过矢量计算来表达。在上面的图像分类问题中，假设softmax回归的权重和偏差参数分别为<br><img src="https://img-blog.csdnimg.cn/20200214141831743.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>设高和宽分别为2个像素的图像样本i的特征为<br><img src="https://img-blog.csdnimg.cn/20200214141906591.jpg" alt="在这里插入图片描述"><br>输出层的输出为<br><img src="https://img-blog.csdnimg.cn/20200214141942367.jpg" alt="在这里插入图片描述"><br>预测为狗、猫或鸡的概率分布为<br><img src="https://img-blog.csdnimg.cn/20200214142013490.jpg" alt="在这里插入图片描述"><br>softmax回归对样本i分类的矢量计算表达式为<br><img src="https://img-blog.csdnimg.cn/2020021414210973.png" alt="在这里插入图片描述"></p><h4 id="1-4-2小批量矢量计算表达式"><a href="#1-4-2小批量矢量计算表达式" class="headerlink" title="1.4.2小批量矢量计算表达式"></a>1.4.2小批量矢量计算表达式</h4><p><img src="https://img-blog.csdnimg.cn/20200214142146320.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h3 id="1-5交叉熵损失函数"><a href="#1-5交叉熵损失函数" class="headerlink" title="1.5交叉熵损失函数"></a>1.5交叉熵损失函数</h3><p><img src="https://img-blog.csdnimg.cn/20200214142303851.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>改善上述问题的一个方法是使用更适合衡量两个概率分布差异的测量函数。其中，交叉熵（cross entropy）是一个常用的衡量方法：<br><img src="https://img-blog.csdnimg.cn/20200214142323890.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200214142336511.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h3 id="1-6模型训练和预测"><a href="#1-6模型训练和预测" class="headerlink" title="1.6模型训练和预测"></a>1.6模型训练和预测</h3><p>在训练好softmax回归模型后，给定任一样本特征，就可以预测每个输出类别的概率。通常，我们把预测概率最大的类别作为输出类别。如果它与真实类别（标签）一致，说明这次预测是正确的。我们将使用准确率（accuracy）来评价模型的表现。它等于正确预测数量与总预测数量之比。</p><h2 id="2-softmax回归模型的两种实现"><a href="#2-softmax回归模型的两种实现" class="headerlink" title="2.softmax回归模型的两种实现"></a>2.softmax回归模型的两种实现</h2><p>方式一：从零开始实现，实现一个对Fashion-MNIST训练集中的图像数据进行分类的模型<br>方式二：使用pytorch重新实现softmax回归模型<br>代码与讲解链接：<a href="https://www.kesci.com/org/boyuai/workspace/project" target="_blank" rel="noopener">添加链接描述</a><br>帮助理解softmax函数的博客：<a href="https://blog.csdn.net/lz_peter/article/details/84574716" target="_blank" rel="noopener">添加链接描述</a></p><p><strong>习题练习：</strong><br><img src="https://img-blog.csdnimg.cn/20200214142934761.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h1 id="三、多层感知机"><a href="#三、多层感知机" class="headerlink" title="三、多层感知机"></a><strong>三、多层感知机</strong></h1><p>我们已经介绍了包括线性回归和softmax回归在内的单层神经网络。然而深度学习主要关注多层模型。我们将以多层感知机（multilayer perceptron，MLP）为例，介绍多层神经网络的概念。<br><strong>主要内容：<br>1.多层感知机的基本知识<br>2.使用多层感知机图像分类的两种实现</strong></p><h2 id="1-多层感知机的基本知识"><a href="#1-多层感知机的基本知识" class="headerlink" title="1.多层感知机的基本知识"></a>1.多层感知机的基本知识</h2><h3 id="1-1隐藏层"><a href="#1-1隐藏层" class="headerlink" title="1.1隐藏层"></a>1.1隐藏层</h3><p>多层感知机在单层神经网络的基础上引入了一到多个隐藏层（hidden layer）。<br>下图展示了一个多层感知机的神经网络图，它含有一个隐藏层，该层中有5个隐藏单元。<br><img src="https://img-blog.csdnimg.cn/20200214143441170.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/2020021414362463.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h3 id="1-2激活函数"><a href="#1-2激活函数" class="headerlink" title="1.2激活函数"></a>1.2激活函数</h3><p>上述问题的根源在于全连接层只是对数据做仿射变换（affine transformation），而多个仿射变换的叠加仍然是一个仿射变换。解决问题的一个方法是引入非线性变换，例如对隐藏变量使用按元素运算的非线性函数进行变换，然后再作为下一个全连接层的输入。这个非线性函数被称为激活函数（activation function）。<br>下面我们介绍几个常用的激活函数：</p><p><strong>ReLU函数</strong><br>ReLU（rectified linear unit）函数提供了一个很简单的非线性变换。给定元素 x ，该函数定义为<br><img src="https://img-blog.csdnimg.cn/20200214143743500.png" alt="在这里插入图片描述"><br>可以看出，ReLU函数只保留正数元素，并将负数元素清零。</p><p><strong>Sigmoid函数</strong><br>sigmoid函数可以将元素的值变换到0和1之间：<br><img src="https://img-blog.csdnimg.cn/2020021414383936.png" alt="在这里插入图片描述"><br><strong>tanh函数</strong><br>tanh（双曲正切）函数可以将元素的值变换到-1和1之间：<br><img src="https://img-blog.csdnimg.cn/20200214143917866.png" alt="在这里插入图片描述"><br>当输入接近0时，tanh函数接近线性变换。虽然该函数的形状和sigmoid函数的形状很像，但tanh函数在坐标系的原点上对称。</p><p><strong>关于激活函数的选择</strong><br>1.ReLu函数是一个通用的激活函数，目前在大多数情况下使用。但是，ReLU函数只能在隐藏层中使用。</p><p>2.用于分类器时，sigmoid函数及其组合通常效果更好。由于梯度消失问题，有时要避免使用sigmoid和tanh函数。</p><p>3.在神经网络层数较多的时候，最好使用ReLu函数，ReLu函数比较简单计算量少，而sigmoid和tanh函数计算量大很多。</p><p>在选择激活函数的时候可以先选用ReLu函数如果效果不理想可以尝试其他激活函数。</p><h3 id="1-3多层感知机"><a href="#1-3多层感知机" class="headerlink" title="1.3多层感知机"></a>1.3多层感知机</h3><p>多层感知机就是含有至少一个隐藏层的由全连接层组成的神经网络，且每个隐藏层的输出通过激活函数进行变换。多层感知机的层数和各隐藏层中隐藏单元个数都是超参数。以单隐藏层为例并沿用本节之前定义的符号，多层感知机按以下方式计算输出：<br><img src="https://img-blog.csdnimg.cn/20200214144113836.png" alt="在这里插入图片描述"></p><h2 id="2-使用多层感知机图像分类的两种实现"><a href="#2-使用多层感知机图像分类的两种实现" class="headerlink" title="2.使用多层感知机图像分类的两种实现"></a>2.使用多层感知机图像分类的两种实现</h2><p>方式一：从零开始实现的实现<br>方式二：使用pytorch的简洁实现<br>代码与讲解链接：<a href="https://www.kesci.com/org/boyuai/workspace/project" target="_blank" rel="noopener">添加链接描述</a><br>帮助理解的博客：<a href="https://blog.csdn.net/fg13821267836/article/details/93405572" target="_blank" rel="noopener">添加链接描述</a></p><p><strong>习题练习：</strong><br><img src="https://img-blog.csdnimg.cn/20200214144346817.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p><strong>参考资料：</strong><br>《动手学深度学习》中文版官网教材：<a href="http://zh.gluon.ai/" target="_blank" rel="noopener">添加链接描述</a><br>PyTorch中文文档：<a href="https://pytorch-cn.readthedocs.io/zh/stable/" target="_blank" rel="noopener">添加链接描述</a></p>]]></content>
      
      
      <categories>
          
          <category> 动手学深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 线性回归 </tag>
            
            <tag> Softmax </tag>
            
            <tag> 多层感知机 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《动手学深度学习》笔记 Task02_文本预处理；语言模型；循环神经网络基础</title>
      <link href="/2020/02/13/article2/"/>
      <url>/2020/02/13/article2/</url>
      
        <content type="html"><![CDATA[<h1 id="一、文本预处理"><a href="#一、文本预处理" class="headerlink" title="一、文本预处理"></a>一、文本预处理</h1><p><strong>主要内容：<br>1.文本预处理的解释<br>2.文本预处理的过程<br>3.现有分词工具</strong></p><h2 id="1-文本预处理的解释"><a href="#1-文本预处理的解释" class="headerlink" title="1.文本预处理的解释"></a>1.文本预处理的解释</h2><p>文本是一类序列数据，一篇文章可以看作是字符或单词的序列，本节将介绍文本数据的常见预处理步骤，预处理通常包括四个步骤：<br><strong>1.读入文本<br>2.分词<br>3.建立字典，将每个词映射到一个唯一的索引（index）<br>4.将文本从词的序列转换为索引的序列，方便输入模型</strong></p><h2 id="2-文本预处理的过程"><a href="#2-文本预处理的过程" class="headerlink" title="2.文本预处理的过程"></a>2.文本预处理的过程</h2><h3 id="2-1读入文本"><a href="#2-1读入文本" class="headerlink" title="2.1读入文本"></a>2.1读入文本</h3><p>我们用一部英文小说，即H. G. Well的Time Machine，作为示例，展示文本预处理的具体过程。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_time_machine</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'/home/kesci/input/timemachine7163/timemachine.txt'</span>, <span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        lines = [re.sub(<span class="string">'[^a-z]+'</span>, <span class="string">' '</span>, line.strip().lower()) <span class="keyword">for</span> line <span class="keyword">in</span> f]</span><br><span class="line">    <span class="keyword">return</span> lines</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">lines = read_time_machine()</span><br><span class="line">print(<span class="string">'# sentences %d'</span> % len(lines))</span><br></pre></td></tr></table></figure><p>out：<br>sentences 3221</p><h3 id="2-2分词"><a href="#2-2分词" class="headerlink" title="2.2分词"></a>2.2分词</h3><p>我们对每个句子进行分词，也就是将一个句子划分成若干个词（token），转换为一个词的序列。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tokenize</span><span class="params">(sentences, token=<span class="string">'word'</span>)</span>:</span></span><br><span class="line">    <span class="string">"""Split sentences into word or char tokens"""</span></span><br><span class="line">    <span class="keyword">if</span> token == <span class="string">'word'</span>:</span><br><span class="line">        <span class="keyword">return</span> [sentence.split(<span class="string">' '</span>) <span class="keyword">for</span> sentence <span class="keyword">in</span> sentences]</span><br><span class="line">    <span class="keyword">elif</span> token == <span class="string">'char'</span>:</span><br><span class="line">        <span class="keyword">return</span> [list(sentence) <span class="keyword">for</span> sentence <span class="keyword">in</span> sentences]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(<span class="string">'ERROR: unkown token type '</span>+token)</span><br><span class="line"></span><br><span class="line">tokens = tokenize(lines)</span><br><span class="line">tokens[<span class="number">0</span>:<span class="number">2</span>]</span><br></pre></td></tr></table></figure><p>out：<br>[[‘the’, ‘time’, ‘machine’, ‘by’, ‘h’, ‘g’, ‘wells’, ‘’], [‘’]]</p><h3 id="2-3建立字典"><a href="#2-3建立字典" class="headerlink" title="2.3建立字典"></a>2.3建立字典</h3><p>为了方便模型处理，我们需要将字符串转换为数字。因此我们需要先构建一个字典（vocabulary），将每个词映射到一个唯一的索引编号。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Vocab</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, tokens, min_freq=<span class="number">0</span>, use_special_tokens=False)</span>:</span></span><br><span class="line">        counter = count_corpus(tokens)  <span class="comment"># : </span></span><br><span class="line">        self.token_freqs = list(counter.items())</span><br><span class="line">        self.idx_to_token = []</span><br><span class="line">        <span class="keyword">if</span> use_special_tokens:</span><br><span class="line">            <span class="comment"># padding, begin of sentence, end of sentence, unknown</span></span><br><span class="line">            self.pad, self.bos, self.eos, self.unk = (<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">            self.idx_to_token += [<span class="string">''</span>, <span class="string">''</span>, <span class="string">''</span>, <span class="string">''</span>]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.unk = <span class="number">0</span></span><br><span class="line">            self.idx_to_token += [<span class="string">''</span>]</span><br><span class="line">        self.idx_to_token += [token <span class="keyword">for</span> token, freq <span class="keyword">in</span> self.token_freqs</span><br><span class="line">                        <span class="keyword">if</span> freq &gt;= min_freq <span class="keyword">and</span> token <span class="keyword">not</span> <span class="keyword">in</span> self.idx_to_token]</span><br><span class="line">        self.token_to_idx = dict()</span><br><span class="line">        <span class="keyword">for</span> idx, token <span class="keyword">in</span> enumerate(self.idx_to_token):</span><br><span class="line">            self.token_to_idx[token] = idx</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> len(self.idx_to_token)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, tokens)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> isinstance(tokens, (list, tuple)):</span><br><span class="line">            <span class="keyword">return</span> self.token_to_idx.get(tokens, self.unk)</span><br><span class="line">        <span class="keyword">return</span> [self.__getitem__(token) <span class="keyword">for</span> token <span class="keyword">in</span> tokens]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">to_tokens</span><span class="params">(self, indices)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> isinstance(indices, (list, tuple)):</span><br><span class="line">            <span class="keyword">return</span> self.idx_to_token[indices]</span><br><span class="line">        <span class="keyword">return</span> [self.idx_to_token[index] <span class="keyword">for</span> index <span class="keyword">in</span> indices]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">count_corpus</span><span class="params">(sentences)</span>:</span></span><br><span class="line">    tokens = [tk <span class="keyword">for</span> st <span class="keyword">in</span> sentences <span class="keyword">for</span> tk <span class="keyword">in</span> st]</span><br><span class="line">    <span class="keyword">return</span> collections.Counter(tokens)  <span class="comment"># 返回一个字典，记录每个词的出现次数</span></span><br></pre></td></tr></table></figure><p>我们看一个例子，这里我们尝试用Time Machine作为语料构建字典</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vocab = Vocab(tokens)</span><br><span class="line">print(list(vocab.token_to_idx.items())[<span class="number">0</span>:<span class="number">10</span>])</span><br></pre></td></tr></table></figure><p>out:<br>[(‘’, 0), (‘the’, 1), (‘time’, 2), (‘machine’, 3), (‘by’, 4), (‘h’, 5), (‘g’, 6), (‘wells’, 7), (‘i’, 8), (‘traveller’, 9)]</p><h3 id="2-3将词转为索引"><a href="#2-3将词转为索引" class="headerlink" title="2.3将词转为索引"></a>2.3将词转为索引</h3><p>使用字典，我们可以将原文本中的句子从单词序列转换为索引序列</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">8</span>, <span class="number">10</span>):</span><br><span class="line">    print(<span class="string">'words:'</span>, tokens[i])</span><br><span class="line">    print(<span class="string">'indices:'</span>, vocab[tokens[i]])</span><br></pre></td></tr></table></figure><p>out:<br>words: [‘the’, ‘time’, ‘traveller’, ‘for’, ‘so’, ‘it’, ‘will’, ‘be’, ‘convenient’, ‘to’, ‘speak’, ‘of’, ‘him’, ‘’]<br>indices: [1, 2, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0]<br>words: [‘was’, ‘expounding’, ‘a’, ‘recondite’, ‘matter’, ‘to’, ‘us’, ‘his’, ‘grey’, ‘eyes’, ‘shone’, ‘and’]<br>indices: [20, 21, 22, 23, 24, 16, 25, 26, 27, 28, 29, 30]</p><h2 id="3-现有分词工具"><a href="#3-现有分词工具" class="headerlink" title="3.现有分词工具"></a>3.现有分词工具</h2><p>我们前面介绍的分词方式非常简单，它至少有以下几个缺点:<br>      1.标点符号通常可以提供语义信息，但是我们的方法直接将其丢弃了<br>      2.类似“shouldn’t”, “doesn’t”这样的词会被错误地处理<br>      3.类似”Mr.”, “Dr.”这样的词会被错误地处理<br>我们可以通过引入更复杂的规则来解决这些问题，但是事实上，有一些现有的工具可以很好地进行分词，我们在这里简单介绍其中的两个：spaCy和NLTK。</p><p>代码讲解和帮助文档链接：<a href="https://www.kesci.com/org/boyuai/workspace/project" target="_blank" rel="noopener">添加链接描述</a></p><p><strong>习题练习：</strong><br><img src="https://img-blog.csdnimg.cn/20200214150040815.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h1 id="二、语言模型"><a href="#二、语言模型" class="headerlink" title="二、语言模型"></a>二、语言模型</h1><p><strong>主要内容：<br>1.语言模型的解释<br>2.n元语法<br>3.语言模型数据集的两种采样方法</strong></p><h2 id="1-语言模型的解释"><a href="#1-语言模型的解释" class="headerlink" title="1.语言模型的解释"></a>1.语言模型的解释</h2><p><img src="https://img-blog.csdnimg.cn/20200214150526777.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h2 id="2-n元语法"><a href="#2-n元语法" class="headerlink" title="2.n元语法"></a>2.n元语法</h2><p><img src="https://img-blog.csdnimg.cn/2020021415060246.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>帮助理解n元语法的博客：<a href="https://blog.csdn.net/wangyangzhizhou/article/details/78651397" target="_blank" rel="noopener">添加链接描述</a></p><h2 id="3-时序数据的采样"><a href="#3-时序数据的采样" class="headerlink" title="3.时序数据的采样"></a>3.时序数据的采样</h2><p>在训练中我们需要每次随机读取小批量样本和标签。与之前章节的实验数据不同的是，时序数据的一个样本通常包含连续的字符。假设时间步数为5，样本序列为5个字符，即“想”“要”“有”“直”“升”。该样本的标签序列为这些字符分别在训练集中的下一个字符，即“要”“有”“直”“升”“机”，即X=“想要有直升”，Y=“要有直升机”。</p><p>现在我们考虑序列“想要有直升机，想要和你飞到宇宙去”，如果时间步数为5，有以下可能的样本和标签：<br><img src="https://img-blog.csdnimg.cn/20200214150656835.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>可以看到，如果序列的长度为T，时间步数为n，那么一共有 T-n 个合法的样本，但是这些样本有大量的重合，我们通常采用更加高效的采样方式。我们有两种方式对时序数据进行采样，分别是随机采样和相邻采样。</p><h3 id="3-1随机采样"><a href="#3-1随机采样" class="headerlink" title="3.1随机采样"></a>3.1随机采样</h3><p>在随机采样中，每个样本是原始序列上任意截取的一段序列，相邻的两个随机小批量在原始序列上的位置不一定相毗邻。</p><h3 id="3-2相邻采样"><a href="#3-2相邻采样" class="headerlink" title="3.2相邻采样"></a>3.2相邻采样</h3><p>在相邻采样中，相邻的两个随机小批量在原始序列上的位置相毗邻。</p><p>代码和帮助理解的文档链接：<a href="https://www.kesci.com/org/boyuai/workspace/project" target="_blank" rel="noopener">添加链接描述</a></p><p>习题练习：<br><img src="https://img-blog.csdnimg.cn/20200214151329997.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h1 id="三、循环神经网络基础"><a href="#三、循环神经网络基础" class="headerlink" title="三、循环神经网络基础"></a>三、循环神经网络基础</h1><p><strong>主要内容：<br>1.循环神经网络的介绍<br>2.循环神经网络的实现</strong></p><h2 id="1-循环神经网络的介绍"><a href="#1-循环神经网络的介绍" class="headerlink" title="1.循环神经网络的介绍"></a>1.循环神经网络的介绍</h2><p><img src="https://img-blog.csdnimg.cn/20200214152510369.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h3 id="1-1循环神经网络的构造"><a href="#1-1循环神经网络的构造" class="headerlink" title="1.1循环神经网络的构造"></a>1.1循环神经网络的构造</h3><p><img src="https://img-blog.csdnimg.cn/2020021415254236.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h3 id="1-2裁剪梯度"><a href="#1-2裁剪梯度" class="headerlink" title="1.2裁剪梯度"></a>1.2裁剪梯度</h3><p><img src="https://img-blog.csdnimg.cn/20200214152626661.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h3 id="1-3困惑度"><a href="#1-3困惑度" class="headerlink" title="1.3困惑度"></a>1.3困惑度</h3><p>我们通常使用困惑度（perplexity）来评价语言模型的好坏。困惑度是对交叉熵损失函数做指数运算后得到的值。特别地，<br><strong>1.最佳情况下，模型总是把标签类别的概率预测为1，此时困惑度为1；<br>2.最坏情况下，模型总是把标签类别的概率预测为0，此时困惑度为正无穷；<br>3.基线情况下，模型总是预测所有类别的概率都相同，此时困惑度为类别个数。</strong><br>显然，任何一个有效模型的困惑度必须小于类别个数。在本例中，困惑度必须小于词典大小vocab_size。</p><h2 id="2-循环神经网络的实现"><a href="#2-循环神经网络的实现" class="headerlink" title="2.循环神经网络的实现"></a>2.循环神经网络的实现</h2><p>代码和解释帮助文档：<a href="https://www.kesci.com/org/boyuai/project/5e42c3ad5f2816002ce979b0" target="_blank" rel="noopener">添加链接描述</a></p><p><strong>习题练习：</strong><br><img src="https://img-blog.csdnimg.cn/20200214153132171.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1cGVyX0NDWQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p><strong>参考资料</strong></p><p>《动手学深度学习》中文版官网教材：<a href="http://zh.gluon.ai/" target="_blank" rel="noopener">添加链接描述</a><br>PyTorch中文文档：<a href="https://pytorch-cn.readthedocs.io/zh/stable/" target="_blank" rel="noopener">添加链接描述</a></p>]]></content>
      
      
      <categories>
          
          <category> 动手学深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文本预处理 </tag>
            
            <tag> 语言模型 </tag>
            
            <tag> 循环神经网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2020/02/10/hello-world/"/>
      <url>/2020/02/10/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
